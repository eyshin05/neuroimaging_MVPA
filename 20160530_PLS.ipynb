{
 "metadata": {
  "name": "",
  "signature": "sha256:91274185e624cc2f3f83d5fa88740c14fe03823f12010544239f6094012aaf9e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mvpa2.suite import *\n",
      "import os\n",
      "import glob\n",
      "import tempfile, shutil"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path_LA = os.path.join('/home', 'brain', 'Desktop', 'LAstudy')\n",
      "dhandle = OpenFMRIDataset(path_LA)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "task = 1\n",
      "model = 1\n",
      "subj = 5\n",
      "# get dataset\n",
      "run_datasets = []\n",
      "for run_id in dhandle.get_task_bold_run_ids(task)[subj]:\n",
      "    run_events = dhandle.get_bold_run_model(model, subj, run_id)\n",
      "    run_ds = dhandle.get_bold_run_dataset(subj, task, run_id, chunks = run_id - 1, flavor = 'preproc',\n",
      "                                          mask = path_LA+'/sub%03d/mask/mask.nii.gz'%(subj))\n",
      "    run_ds.sa['targets'] = events2sample_attr(run_events, run_ds.sa.time_coords, noinfolabel='rest')\n",
      "    run_datasets.append(run_ds)\n",
      "\n",
      "fds = vstack(run_datasets, a=0)\n",
      "\n",
      "# preprocessing\n",
      "poly_detrend(fds, polyord=1, chunks_attr='chunks')\n",
      "\n",
      "# get accurate event list\n",
      "event_names = glob.glob(path_LA+'/sub%03d/model/model001/onsets/task001_run*/cond*.txt'%(subj))\n",
      "event_names.sort()\n",
      "\n",
      "event_list = []\n",
      "for i in range(0,len(event_names),2):\n",
      "    reject = SampleAttributes(event_names[i], header=['onset', 'duration', 'dummy'])\n",
      "    accept = SampleAttributes(event_names[i+1], header=['onset', 'duration', 'dummy'])\n",
      "    event_list1 = [Event(chunks=i/2, onset=reject.onset[j], duration=3, targets='0') for j in range(len(reject.onset))]\n",
      "    event_list2 = [Event(chunks=i/2, onset=accept.onset[j], duration=3, targets='1') for j in range(len(accept.onset))]\n",
      "    event_list.extend(sorted(event_list1 + event_list2, key=lambda event: event['onset'])[:-2])\n",
      "\n",
      "evds = fit_event_hrf_model(fds, event_list, time_attr = 'time_coords', condition_attr=('targets', 'chunks'), glmfit_kwargs=dict(model='ols'))\n",
      "\n",
      "# training and cross validation\n",
      "zscore(evds, chunks_attr = None)\n",
      "clf = kNN(k = 1, dfx = one_minus_correlation, voting = 'majority')\n",
      "cv = CrossValidation(clf, NFoldPartitioner(attr='chunks'))\n",
      "cv_glm = cv(evds)\n",
      "print np.mean(cv_glm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.333333333333\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get dataset\n",
      "run_datasets = []\n",
      "for run_id in dhandle.get_task_bold_run_ids(task)[subj]:\n",
      "    run_events = dhandle.get_bold_run_model(model, subj, run_id)\n",
      "    run_ds = dhandle.get_bold_run_dataset(subj, task, run_id, chunks = run_id - 1, flavor = 'preproc',\n",
      "                                          mask = path_LA+'/sub%03d/mask/mask.nii.gz'%(subj))\n",
      "    run_ds.sa['targets'] = events2sample_attr(run_events, run_ds.sa.time_coords, noinfolabel='rest')\n",
      "    run_datasets.append(run_ds)\n",
      "\n",
      "fds = vstack(run_datasets, a=0)\n",
      "\n",
      "# preprocessing\n",
      "poly_detrend(fds, polyord=1, chunks_attr='chunks')\n",
      "\n",
      "# get accurate event list\n",
      "event_names = glob.glob(path_LA+'/sub%03d/model/model001/onsets/task001_run*/cond*.txt'%(subj))\n",
      "event_names.sort()\n",
      "\n",
      "event_list = []\n",
      "for i in range(0,len(event_names),2):\n",
      "    reject = SampleAttributes(event_names[i], header=['onset', 'duration', 'dummy'])\n",
      "    accept = SampleAttributes(event_names[i+1], header=['onset', 'duration', 'dummy'])\n",
      "    event_list1 = [Event(chunks=i/2, onset=reject.onset[j], duration=3, targets='0') for j in range(len(reject.onset))]\n",
      "    event_list2 = [Event(chunks=i/2, onset=accept.onset[j], duration=3, targets='1') for j in range(len(accept.onset))]\n",
      "    event_list.extend(sorted(event_list1 + event_list2, key=lambda event: event['onset'])[:-2])\n",
      "\n",
      "evds = fit_event_hrf_model(fds, event_list, time_attr = 'time_coords', condition_attr=('targets', 'chunks'))\n",
      "\n",
      "# training and cross validation\n",
      "zscore(evds, chunks_attr = None)\n",
      "clf = kNN(k = 1, dfx = one_minus_correlation, voting = 'majority')\n",
      "cv = CrossValidation(clf, NFoldPartitioner(attr='chunks'))\n",
      "cv_glm = cv(evds)\n",
      "print np.mean(cv_glm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.333333333333\n"
       ]
      }
     ],
     "prompt_number": 15
    }
   ],
   "metadata": {}
  }
 ]
}