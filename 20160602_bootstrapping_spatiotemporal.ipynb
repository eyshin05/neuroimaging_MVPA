{
 "metadata": {
  "name": "",
  "signature": "sha256:9f17117e6941d003d15accb8d28b41343354915627f71c959958c8814a2524ce"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mvpa2.suite import *\n",
      "import os\n",
      "import glob\n",
      "import tempfile, shutil\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path_LA = os.path.join('/home', 'brain', 'Desktop', 'LAstudy')\n",
      "dhandle = OpenFMRIDataset(path_LA)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_dataset(task, model, subj):\n",
      "    # get dataset\n",
      "    run_datasets = []\n",
      "    for run_id in dhandle.get_task_bold_run_ids(task)[subj]:\n",
      "        run_events = dhandle.get_bold_run_model(model, subj, run_id)\n",
      "        run_ds = dhandle.get_bold_run_dataset(subj, task, run_id, chunks = run_id - 1, flavor = 'filtered',\n",
      "                                              mask = path_LA+'/sub%03d/mask/mask.nii.gz'%(subj))\n",
      "        run_ds.sa['targets'] = events2sample_attr(run_events, run_ds.sa.time_coords, noinfolabel='rest')\n",
      "        run_datasets.append(run_ds)\n",
      "\n",
      "    fds = vstack(run_datasets, a=0)\n",
      "    \n",
      "    # preprocessing\n",
      "    poly_detrend(fds, polyord=1, chunks_attr='chunks')\n",
      "    \n",
      "    return fds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# return order: reject, accept\n",
      "def get_eventlist_each(subj):\n",
      "    # get accurate event list\n",
      "    event_names = glob.glob(path_LA+'/sub%03d/model/model001/onsets/task001_run*/cond*.txt'%(subj))\n",
      "    event_names.sort()\n",
      "    \n",
      "    event_list1 = []\n",
      "    event_list2 = []\n",
      "\n",
      "    for i in range(0,len(event_names),2):\n",
      "        reject = SampleAttributes(event_names[i], header=['onset', 'duration', 'dummy'])\n",
      "        accept = SampleAttributes(event_names[i+1], header=['onset', 'duration', 'dummy'])\n",
      "        event_list1.extend([Event(chunks=i/2, onset=reject.onset[j], duration=3, targets='reject') for j in range(len(reject.onset))][:-2])\n",
      "        event_list2.extend([Event(chunks=i/2, onset=accept.onset[j], duration=3, targets='accept') for j in range(len(accept.onset))][:-2])\n",
      "\n",
      "    for ev in event_list1:\n",
      "        ev['onset'] -= 2\n",
      "        ev['duration'] = 13    \n",
      "\n",
      "    for ev in event_list2:\n",
      "        ev['onset'] -= 2\n",
      "        ev['duration'] = 13\n",
      "        \n",
      "    return event_list1, event_list2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_bootstrapped_dataset(ds, events, n=300):\n",
      "    events_idx = np.random.choice(len(events), n)\n",
      "    events_idx.sort()\n",
      "    boot_events = [events[idx] for idx in events_idx]\n",
      "    evds = eventrelated_dataset(ds, events=boot_events)\n",
      "    \n",
      "    return evds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bootstrapping(subj):\n",
      "    fds = get_dataset(1, 1, subj)\n",
      "\n",
      "    event_rj, event_ac = get_eventlist_each(subj)\n",
      "    evds_rj = get_bootstrapped_dataset(fds, event_rj, 50)\n",
      "    evds_ac = get_bootstrapped_dataset(fds, event_ac, 50)\n",
      "    \n",
      "    run_datasets = []\n",
      "    run_datasets.append(evds_ac)\n",
      "    run_datasets.append(evds_rj)\n",
      "    evds = vstack(run_datasets, a=0)\n",
      "    \n",
      "    zscore(evds, chunks_attr = None)\n",
      "    \n",
      "    return evds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#boot strapping add6\n",
      "for subj in dhandle.get_subj_ids():\n",
      "    #subj = 1\n",
      "    evds = bootstrapping(subj)\n",
      "\n",
      "    h5save(os.path.join('/data/20160601/', 'bs_spatiotemporal', 'sub%03d.hdf5'%subj), evds, compression=9)\n",
      "    loaded = h5load(os.path.join('/data/20160601/', 'bs_spatiotemporal', 'sub%03d.hdf5'%subj))\n",
      "    print np.all(evds.samples == loaded.samples)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 13
    }
   ],
   "metadata": {}
  }
 ]
}