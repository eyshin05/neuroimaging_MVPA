{
 "metadata": {
  "name": "",
  "signature": "sha256:d7deaca0a6701addbd2d802dcccbbede2060ff75f242cad3cad6fc1cda59cb39"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mvpa2.suite import *\n",
      "import os\n",
      "import glob\n",
      "import tempfile, shutil"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path_LA = os.path.join('/home', 'brain', 'Desktop', 'LAstudy')\n",
      "dhandle = OpenFMRIDataset(path_LA)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# HRF-ols (LS-A model)\n",
      "task = 1\n",
      "model = 1\n",
      "for subj in dhandle.get_subj_ids():\n",
      "    # get dataset\n",
      "    run_datasets = []\n",
      "    for run_id in dhandle.get_task_bold_run_ids(task)[subj]:\n",
      "        run_events = dhandle.get_bold_run_model(model, subj, run_id)\n",
      "        run_ds = dhandle.get_bold_run_dataset(subj, task, run_id, chunks = run_id - 1, flavor = 'filtered',\n",
      "                                              mask = path_LA+'/sub%03d/mask/mask.nii.gz'%(subj))\n",
      "        run_ds.sa['targets'] = events2sample_attr(run_events, run_ds.sa.time_coords, noinfolabel='rest')\n",
      "        run_datasets.append(run_ds)\n",
      "\n",
      "    fds = vstack(run_datasets, a=0)\n",
      "    \n",
      "    # preprocessing\n",
      "    poly_detrend(fds, polyord=1, chunks_attr='chunks')\n",
      "    \n",
      "    # get accurate event list\n",
      "    event_names = glob.glob(path_LA+'/sub%03d/model/model001/onsets/task001_run*/cond*.txt'%(subj))\n",
      "    event_names.sort()\n",
      "    \n",
      "    event_list = []\n",
      "    for i in range(0,len(event_names),2):\n",
      "        reject = SampleAttributes(event_names[i], header=['onset', 'duration', 'dummy'])\n",
      "        accept = SampleAttributes(event_names[i+1], header=['onset', 'duration', 'dummy'])\n",
      "        event_list1 = [Event(chunks=i/2, onset=reject.onset[j], duration=3, targets='reject') for j in range(len(reject.onset))]\n",
      "        event_list2 = [Event(chunks=i/2, onset=accept.onset[j], duration=3, targets='accept') for j in range(len(accept.onset))]\n",
      "        event_list.extend(sorted(event_list1 + event_list2, key=lambda event: event['onset']))\n",
      "        \n",
      "    evds = fit_event_hrf_model(fds, event_list, time_attr = 'time_coords', condition_attr=('targets', 'chunks'), \n",
      "                               glmfit_kwargs = dict(model='ols')) \n",
      "    \n",
      "    # training and cross validation\n",
      "    zscore(evds, chunks_attr = None)\n",
      "\n",
      "    # save evds... hrf models\n",
      "    h5save(os.path.join('/data/20160601/', 'hrf', 'sub%03d.hdf5'%subj), evds, compression=9)\n",
      "    loaded = h5load(os.path.join('/data/20160601/', 'hrf', 'sub%03d.hdf5'%subj))\n",
      "    print np.all(evds.samples == loaded.samples)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# spatio temporal\n",
      "for subj in dhandle.get_subj_ids():\n",
      "    # get dataset\n",
      "    run_datasets = []\n",
      "    for run_id in dhandle.get_task_bold_run_ids(task)[subj]:\n",
      "        run_events = dhandle.get_bold_run_model(model, subj, run_id)\n",
      "        run_ds = dhandle.get_bold_run_dataset(subj, task, run_id, chunks = run_id - 1, flavor = 'filtered',\n",
      "                                              mask = path_LA+'/sub%03d/mask/mask.nii.gz'%(subj))\n",
      "        run_ds.sa['targets'] = events2sample_attr(run_events, run_ds.sa.time_coords, noinfolabel='rest')\n",
      "        run_datasets.append(run_ds)\n",
      "\n",
      "    fds = vstack(run_datasets, a=0)\n",
      "    \n",
      "    # preprocessing\n",
      "    poly_detrend(fds, polyord=1, chunks_attr='chunks')\n",
      "    \n",
      "    # get accurate event list\n",
      "    event_names = glob.glob(path_LA+'/sub%03d/model/model001/onsets/task001_run*/cond*.txt'%(subj))\n",
      "    event_names.sort()\n",
      "    \n",
      "    event_list = []\n",
      "    for i in range(0,len(event_names),2):\n",
      "        reject = SampleAttributes(event_names[i], header=['onset', 'duration', 'dummy'])\n",
      "        accept = SampleAttributes(event_names[i+1], header=['onset', 'duration', 'dummy'])\n",
      "        event_list1 = [Event(chunks=i/2, onset=reject.onset[j], duration=3, targets='reject') for j in range(len(reject.onset))]\n",
      "        event_list2 = [Event(chunks=i/2, onset=accept.onset[j], duration=3, targets='accept') for j in range(len(accept.onset))]\n",
      "        event_list.extend(sorted(event_list1 + event_list2, key=lambda event: event['onset'])[:-2]) #slice last two samples\n",
      "        \n",
      "    event_duration = 13\n",
      "    for ev in event_list:\n",
      "        ev['onset'] -= 2\n",
      "        ev['duration'] = event_duration    \n",
      "    \n",
      "    evds = eventrelated_dataset(fds, events=event_list)\n",
      "    \n",
      "    # training and cross validation\n",
      "    zscore(evds, chunks_attr = None)\n",
      "\n",
      "    # save evds... hrf models\n",
      "    h5save(os.path.join('/data/20160601/', 'spatiotemporal', 'sub%03d.hdf5'%subj), evds, compression=9)\n",
      "    loaded = h5load(os.path.join('/data/20160601/', 'spatiotemporal', 'sub%03d.hdf5'%subj))\n",
      "    print np.all(evds.samples == loaded.samples)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/dist-packages/mvpa2/mappers/boxcar.py:148: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  return np.vstack([data[box][np.newaxis] for box in self.__selectors])\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# add 6\n",
      "for subj in dhandle.get_subj_ids():\n",
      "    # get dataset\n",
      "    run_datasets = []\n",
      "    for run_id in dhandle.get_task_bold_run_ids(task)[subj]:\n",
      "        run_events = dhandle.get_bold_run_model(model, subj, run_id)\n",
      "        run_ds = dhandle.get_bold_run_dataset(subj, task, run_id, chunks = run_id - 1, flavor = 'filtered',\n",
      "                                              mask = path_LA+'/sub%03d/mask/mask.nii.gz'%(subj))\n",
      "        run_ds.sa['targets'] = events2sample_attr(run_events, run_ds.sa.time_coords, noinfolabel='rest')\n",
      "        run_datasets.append(run_ds)\n",
      "\n",
      "    fds = vstack(run_datasets, a=0)\n",
      "    \n",
      "    # preprocessing\n",
      "    poly_detrend(fds, polyord=1, chunks_attr='chunks')\n",
      "    \n",
      "    # get accurate event list\n",
      "    event_names = glob.glob(path_LA+'/sub%03d/model/model001/onsets/task001_run*/cond*.txt'%(subj))\n",
      "    event_names.sort()\n",
      "    \n",
      "    event_list = []\n",
      "    for i in range(0,len(event_names),2):\n",
      "        reject = SampleAttributes(event_names[i], header=['onset', 'duration', 'dummy'])\n",
      "        accept = SampleAttributes(event_names[i+1], header=['onset', 'duration', 'dummy'])\n",
      "        event_list1 = [Event(chunks=i/2, onset=reject.onset[j], duration=3, targets='reject') for j in range(len(reject.onset))]\n",
      "        event_list2 = [Event(chunks=i/2, onset=accept.onset[j], duration=3, targets='accept') for j in range(len(accept.onset))]\n",
      "        event_list.extend(sorted(event_list1 + event_list2, key=lambda event: event['onset'])[:-2]) #slice last two samples\n",
      "        \n",
      "    for ev in event_list:\n",
      "        ev['onset'] += 6\n",
      "        ev['duration'] = 2\n",
      "        \n",
      "    evds = eventrelated_dataset(fds, events=event_list)\n",
      "    \n",
      "    # training and cross validation\n",
      "    zscore(evds, chunks_attr = None)\n",
      "\n",
      "    # save evds... hrf models\n",
      "    h5save(os.path.join('/data/20160601/', 'add6', 'sub%03d.hdf5'%subj), evds, compression=9)\n",
      "    loaded = h5load(os.path.join('/data/20160601/', 'add6', 'sub%03d.hdf5'%subj))\n",
      "    print np.all(evds.samples == loaded.samples)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "True"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 21
    }
   ],
   "metadata": {}
  }
 ]
}